{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdcc38ff",
   "metadata": {},
   "source": [
    "This script will generate event files for the R_A_ID experiment for each participant. For example, for `subject 10`, it will generate:\n",
    "* *sub-10_ses-1_task-gain1_cond.csv*\n",
    "* *sub-10_ses-1_task-gain2_cond.csv*\n",
    "* *sub-10_ses-1_task-loss1_cond.csv*\n",
    "* *sub-10_ses-1_task-loss2_cond.csv*\n",
    "* *sub-10_ses-2_task-loss1_cond.csv*\n",
    "* *sub-10_ses-2_task-loss2_cond.csv*\n",
    "* *sub-10_ses-2_task-gain1_cond.csv*\n",
    "* *sub-10_ses-2_task-gain2_cond.csv*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350284ac",
   "metadata": {},
   "source": [
    "Necessary inputs are the MATLAB data files for each participant, e.g. for `subject 10`:\n",
    "* *RA_GAINS_10.mat* that has all the data from 2 gain blocks on day 1 and 2 gain blocks on day 2\n",
    "* *RA_LOSS_10.mat* that has all the data from 2 loss blocks on day 1 and 2 loss blocks on day 2\n",
    "\n",
    "\n",
    "Optional inputs are the model-fitted paramaters. For the ambigNrisk model, this includes `alpha` and `beta` for gains and losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45b909a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.io as spio\n",
    "from glob import glob\n",
    "from scipy import stats\n",
    "import datetime\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d65c693e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory with the behavioral data (i.e. RA_GAINS_10 or RA_LOSS_10)\n",
    "data_behav_root = 'D:\\\\Chelsea\\\\Projects_in_the_lab\\\\RAID\\\\behavioral'\n",
    "\n",
    "# directory for saving the event files\n",
    "out_root = 'D:\\\\Chelsea\\\\Projects_in_the_lab\\\\RAID\\\\output\\\\event_files'\n",
    "\n",
    "# subjects for imaging analysis\n",
    "sub_num = [11,12,13,15,16,17,19,20,21,22,24,25,27,28,29,30,31,32,36,39,40,41,42,43,45,46,47,48,50,51,55,56,57,61,62]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7e909a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>alpha_mon</th>\n",
       "      <th>beta_mon</th>\n",
       "      <th>gamma_mon</th>\n",
       "      <th>LL_mon</th>\n",
       "      <th>r2_adj_mon</th>\n",
       "      <th>AIC_mon</th>\n",
       "      <th>BIC_mon</th>\n",
       "      <th>model_mon</th>\n",
       "      <th>exitFlag_mon</th>\n",
       "      <th>optimizer_mon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>0.973936</td>\n",
       "      <td>-0.136303</td>\n",
       "      <td>-2.480348</td>\n",
       "      <td>-9.689934</td>\n",
       "      <td>0.852357</td>\n",
       "      <td>25.379867</td>\n",
       "      <td>33.840712</td>\n",
       "      <td>ambigNrisk</td>\n",
       "      <td>1</td>\n",
       "      <td>fminunc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>1.268806</td>\n",
       "      <td>0.283613</td>\n",
       "      <td>-1.382632</td>\n",
       "      <td>-8.487385</td>\n",
       "      <td>0.866348</td>\n",
       "      <td>22.974770</td>\n",
       "      <td>31.435615</td>\n",
       "      <td>ambigNrisk</td>\n",
       "      <td>1</td>\n",
       "      <td>fminunc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>0.743337</td>\n",
       "      <td>0.142045</td>\n",
       "      <td>-1.456520</td>\n",
       "      <td>-31.293190</td>\n",
       "      <td>0.601011</td>\n",
       "      <td>68.586380</td>\n",
       "      <td>77.047225</td>\n",
       "      <td>ambigNrisk</td>\n",
       "      <td>1</td>\n",
       "      <td>fminunc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>0.839222</td>\n",
       "      <td>0.444468</td>\n",
       "      <td>-1.747722</td>\n",
       "      <td>-21.413541</td>\n",
       "      <td>0.715957</td>\n",
       "      <td>48.827083</td>\n",
       "      <td>57.287927</td>\n",
       "      <td>ambigNrisk</td>\n",
       "      <td>1</td>\n",
       "      <td>fminunc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>1.154750</td>\n",
       "      <td>-0.137953</td>\n",
       "      <td>-0.723317</td>\n",
       "      <td>-20.295367</td>\n",
       "      <td>0.728967</td>\n",
       "      <td>46.590735</td>\n",
       "      <td>55.051580</td>\n",
       "      <td>ambigNrisk</td>\n",
       "      <td>1</td>\n",
       "      <td>fminunc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  alpha_mon  beta_mon  gamma_mon     LL_mon  r2_adj_mon    AIC_mon  \\\n",
       "0  11   0.973936 -0.136303  -2.480348  -9.689934    0.852357  25.379867   \n",
       "1  12   1.268806  0.283613  -1.382632  -8.487385    0.866348  22.974770   \n",
       "2  13   0.743337  0.142045  -1.456520 -31.293190    0.601011  68.586380   \n",
       "3  15   0.839222  0.444468  -1.747722 -21.413541    0.715957  48.827083   \n",
       "4  16   1.154750 -0.137953  -0.723317 -20.295367    0.728967  46.590735   \n",
       "\n",
       "     BIC_mon   model_mon  exitFlag_mon optimizer_mon  \n",
       "0  33.840712  ambigNrisk             1       fminunc  \n",
       "1  31.435615  ambigNrisk             1       fminunc  \n",
       "2  77.047225  ambigNrisk             1       fminunc  \n",
       "3  57.287927  ambigNrisk             1       fminunc  \n",
       "4  55.051580  ambigNrisk             1       fminunc  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read model-fitted parameters to calculate SV\n",
    "data_model_root = 'D:\\\\Chelsea\\\\Projects_in_the_lab\\\\RAID\\\\model_results'\n",
    "\n",
    "# parameters for each participant in gains\n",
    "par_gain = pd.read_csv(os.path.join(data_model_root, 'Behavior data fitpar_12012022', 'param_12012022.csv'))\n",
    "\n",
    "# parameters for each participant in losses\n",
    "par_loss = pd.read_csv(os.path.join(data_model_root, 'Behavior data fitpar_12012022loss2', 'param_12012022loss2.csv'))\n",
    "\n",
    "par_gain.head()\n",
    "par_loss.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b85029",
   "metadata": {},
   "source": [
    "Depending on the model, par should contain:\n",
    "* ambigNrisk: `alpha`, `beta`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62c88a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% calculate SV\n",
    "def ambig_utility(sub_id, par, p, a, obj_val, domain, model):\n",
    "    '''\n",
    "    Calcualte subjective value based on model\n",
    "    For a list of trials\n",
    "    \n",
    "    Input:\n",
    "        sub_id: subject id\n",
    "        par: panda data frame of all subjects' parameter fits\n",
    "        p: probability of lotteries, vector\n",
    "        a: ambiguity of lotteries, vector\n",
    "        obj_val: objective value of lottery pary-offs, vector\n",
    "        domain: 'gains' or 'loss'\n",
    "        model: named of the subjective value model\n",
    "        \n",
    "    Output:\n",
    "        sv: subjective values of lotteries, vector\n",
    "    '''\n",
    "    par_sub = par[(par.id == sub_id)]\n",
    "            \n",
    "    if model == 'ambigNrisk':\n",
    "        alpha = par_sub.iloc[0]['alpha_mon']\n",
    "        beta = par_sub.iloc[0]['beta_mon']\n",
    "        if domain == 'gains':    \n",
    "            sv = (p - beta * a/2) * obj_val**alpha\n",
    "            \n",
    "            ref_sv = np.ones(obj_val.shape) * 5** alpha\n",
    "        else:\n",
    "            sv = (p - beta * a/2) * -(abs(obj_val)**alpha)\n",
    "            \n",
    "            ref_sv = np.ones(obj_val.shape) * -5** alpha\n",
    "    return sv, ref_sv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa2c13cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% calculate model-estimated risk level\n",
    "def reward_probability(sub_id, par, p, a):\n",
    "    '''\n",
    "    Calculate subjective value based on model\n",
    "    For a list of trials\n",
    "    \n",
    "    Input:\n",
    "        sub_id: subject id\n",
    "        par: panda data frame of all subjects' parameter fits\n",
    "        p: probability of lotteries, vector\n",
    "        a: ambiguity of lotteries, vector\n",
    "        domain_idx: domian index, 1-medical, 0-monetary\n",
    "        \n",
    "    Output:\n",
    "        risk_level: risk level (reward probability) of lotteries, vector. For \n",
    "        risky trials, these are just the reward probability. For ambiguous\n",
    "        trials, these are the model-estimated reward probability.\n",
    "    '''    \n",
    "    \n",
    "    par_sub = par[(par.id == sub_id)]\n",
    "    beta = par_sub.iloc[0]['beta_mon']\n",
    "    \n",
    "    reward_prob = p - beta * a/2\n",
    "    \n",
    "    return reward_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43abd2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _todict(matobj):\n",
    "    '''\n",
    "    Author: Or\n",
    "    \n",
    "    A recursive function which constructs from matobjects nested dictionaries\n",
    "    '''\n",
    "    dict = {}\n",
    "    for strg in matobj._fieldnames:\n",
    "        elem = matobj.__dict__[strg]\n",
    "        if isinstance(elem, spio.matlab.mio5_params.mat_struct):\n",
    "            dict[strg] = _todict(elem)\n",
    "        else:\n",
    "            dict[strg] = elem\n",
    "    return dict\n",
    "\n",
    "def _check_keys(dict):\n",
    "    '''\n",
    "    Author: Or\n",
    "    \n",
    "    checks if entries in dictionary are mat-objects. If yes todict is called to change them to nested dictionaries\n",
    "    '''\n",
    "    for key in dict:\n",
    "        if isinstance(dict[key], spio.matlab.mio5_params.mat_struct):\n",
    "            dict[key] = _todict(dict[key])\n",
    "    return dict \n",
    "\n",
    "def loadmat(filename):\n",
    "    '''\n",
    "    Author: Or\n",
    "    \n",
    "    this function should be called instead of direct spio.loadmat\n",
    "    as it cures the problem of not properly recovering python dictionaries\n",
    "    from mat files. It calls the function check keys to cure all entries\n",
    "    which are still mat-objects\n",
    "    \n",
    "    from: `StackOverflow <http://stackoverflow.com/questions/7008608/scipy-io-loadmat-nested-structures-i-e-dictionaries>`_\n",
    "    '''\n",
    "    data = spio.loadmat(filename, struct_as_record=False, squeeze_me=True)\n",
    "    return _check_keys(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b3b18d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readConditions(subNum, domain, matFile, x): # takes name of file and when to begin (i.e. first block is zero. second is 21 etc.)\n",
    "    \"\"\" read condition onset and duration\n",
    "    \n",
    "    Parameters\n",
    "    -------------\n",
    "    subNum: subject id\n",
    "    domain: domain name, 'gains' or 'loss'\n",
    "    matFile: filename\n",
    "    x: trial index at the begining of each block\n",
    "    \n",
    "    Return\n",
    "    -------------\n",
    "    events\n",
    "    \"\"\"\n",
    "    \n",
    "    metaData = loadmat(matFile)    \n",
    "    # get the key names for the data, as half is 'Datamed', half is 'Datamon'\n",
    "    data_keyname = list(metaData.keys())[3]    \n",
    "    # trial number per block\n",
    "    trial_num = 31 \n",
    "    \n",
    "    if domain == 'Loss':\n",
    "        domain_idx = 1\n",
    "    else:\n",
    "        domain_idx = 0\n",
    "        \n",
    "    \n",
    "    # rating\n",
    "    #rating_sub = rating[(rating.id == subNum) & (rating.is_med == domain_idx)]\n",
    "    \n",
    "    timeStamp = []\n",
    "    condition = []\n",
    "    events = []\n",
    "    resultsArray = []\n",
    "    duration = []\n",
    "    resp_array =[]\n",
    "    resp_onset = []\n",
    "    resp_duration = []\n",
    "   \n",
    "    ambigs = metaData[data_keyname]['ambigs']\n",
    "    probs = metaData[data_keyname]['probs']\n",
    "    if domain == 'gains':\n",
    "        vals = metaData[data_keyname]['vals']\n",
    "        svs, ref_svs = ambig_utility(subNum, par_gain, probs, ambigs, vals, domain, 'ambigNrisk')\n",
    "        reward_prob = reward_probability(subNum, par_gain, probs, ambigs)\n",
    "    else:\n",
    "        vals = -1*metaData[data_keyname]['vals']\n",
    "        svs, ref_svs = ambig_utility(subNum, par_loss, probs, ambigs, vals, domain, 'ambigNrisk')\n",
    "        reward_prob = reward_probability(subNum, par_loss, probs, ambigs)\n",
    "    choice = metaData[data_keyname]['choice']\n",
    "    refside = metaData[data_keyname]['refSide']\n",
    "    \n",
    "    # calculate response from choice and refside\n",
    "    resp = np.ones(choice.shape) # 1-choose lottery\n",
    "    resp[choice == refside] = 0 # 0-choose reference\n",
    "    resp[choice == 0] = 2 # 2-no response\n",
    "    \n",
    "    # x= 0 # where to start\n",
    "    for i in range(x, x+trial_num):\n",
    "        #a= metaData['Data']['trialTime'][i]\n",
    "        #b = vars(a)\n",
    "        \n",
    "        # trial onset \n",
    "        resultsArray = vars(metaData[data_keyname]['trialTime'][i])['trialStartTime'] - vars(metaData[data_keyname]['trialTime'][x])['trialStartTime']\n",
    "        timeStamp.append(int(round((3600*resultsArray[3] + 60*resultsArray[4] + resultsArray[5])))) # using int and round to round to the close integer. \n",
    "        \n",
    "        # response onset\n",
    "        #resp_array = vars(metaData[data_keyname]['trialTime'][i])['respStartTime'] - vars(metaData[data_keyname]['trialTime'][x])['trialStartTime']\n",
    "        #resp_onset.append(int(round((3600*resp_array[3] + 60*resp_array[4] + resp_array[5])))) # using int and round to round to the close integer.\n",
    "        #resp_d = vars(metaData[data_keyname]['trialTime'][i])['feedbackStartTime'] - vars(metaData[data_keyname]['trialTime'][i])['respStartTime']\n",
    "        #resp_duration.append(int(round((3600*resp_d[3] + 60*resp_d[4] + resp_d[5]))))\n",
    "        \n",
    "        duration.append(6)\n",
    "       \n",
    "        if ambigs[i] == 0:\n",
    "            condition.append('risk')\n",
    "        else:\n",
    "            condition.append('amb')\n",
    "    \n",
    "    events= pd.DataFrame({'trial_type':condition, 'onset':timeStamp, 'duration':duration, \n",
    "                          'probs': probs[range(x, x+trial_num)], 'ambigs': ambigs[range(x, x+trial_num)], 'vals': vals[range(x, x+trial_num)], \n",
    "                          'svs': np.round(svs[range(x, x+trial_num)], 3), 'ref_svs': np.round(ref_svs[range(x, x+trial_num)], 3), \n",
    "                          'reward_prob': np.round(reward_prob[range(x, x+trial_num)], 3),\n",
    "                          'resp': resp[range(x, x+trial_num)]})[1:] # building data frame from what we took. Removing first row because its not used. \n",
    "    \n",
    "    return events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fbb6664",
   "metadata": {},
   "outputs": [],
   "source": [
    "def organizeBlocks(subNum):\n",
    "    # Read both mat files (first timestamp)\n",
    "    # check first block of each day. \n",
    "    # check third of each day\n",
    "    # sort\n",
    "    # z score svs\n",
    "    \n",
    "    trial_num = 31 #8 blocks, 31 total trials per block and the first trial will be discarded. should see 30 trials in the event files.\n",
    "    \n",
    "    orderArray = []\n",
    "    \n",
    "    mat_loss_name = os.path.join(data_behav_root, 'RA_LOSS_%s.mat' %subNum)    \n",
    "    mat_gain_name = os.path.join(data_behav_root, 'RA_GAINS_%s.mat' %subNum)    \n",
    "    \n",
    "    metaDataLoss = loadmat(mat_loss_name)\n",
    "    data_loss_keyname = list(metaDataLoss.keys())[3]\n",
    "    metaDataGain = loadmat(mat_gain_name)\n",
    "    data_gain_keyname = list(metaDataGain.keys())[3]\n",
    "    \n",
    "    # trial start time of the 1st and the 3rd block in each domain\n",
    "    a= {'1stLoss':list(vars(metaDataLoss[data_loss_keyname]['trialTime'][0])['trialStartTime']), \n",
    "        '3rdLoss':list(vars(metaDataLoss[data_loss_keyname]['trialTime'][trial_num*2])['trialStartTime']), \n",
    "        '1stGain':list(vars(metaDataGain[data_gain_keyname]['trialTime'][0])['trialStartTime']), \n",
    "        '3rdGain':list(vars(metaDataGain[data_gain_keyname]['trialTime'][trial_num*2])['trialStartTime'])}\n",
    "    # sort by trial start time\n",
    "    s = [(k, a[k]) for k in sorted(a, key=a.get, reverse=False)]\n",
    "    for k, v in s:\n",
    "        print (k, v)\n",
    "        orderArray.append(k)\n",
    "    \n",
    "    totalEvent = []\n",
    "    for n in orderArray:\n",
    "        print (n)\n",
    "        if n=='1stLoss':\n",
    "            # run Med mat file on readConditions function on first two blocks (i.e. 0, 21)\n",
    "            print (n)\n",
    "            for x in [0,trial_num]:\n",
    "                event = readConditions(subNum, 'loss', mat_loss_name, x)\n",
    "                event['condition'] = 'Loss'\n",
    "                event['zsvs'] = stats.zscore(event['svs'])\n",
    "                totalEvent.append(event)\n",
    "        elif n=='1stGain':\n",
    "            # run Mon mat file on readCondition function\n",
    "            print (n)\n",
    "            for x in [0,trial_num]:\n",
    "                event = readConditions(subNum, 'gains', mat_gain_name, x)\n",
    "                event['condition'] = 'Gain'\n",
    "                event['zsvs'] = stats.zscore(event['svs'])\n",
    "                totalEvent.append(event)\n",
    "        elif n=='3rdLoss':\n",
    "            print (n)\n",
    "            for x in [trial_num*2, trial_num*3]:\n",
    "                event = readConditions(subNum, 'loss', mat_loss_name, x)\n",
    "                event['condition'] = 'Loss'\n",
    "                event['zsvs'] = stats.zscore(event['svs'])                \n",
    "                totalEvent.append(event)\n",
    "        elif n=='3rdGain':\n",
    "            # run Mon from 3rd block\n",
    "            print (n)\n",
    "            for x in [trial_num*2, trial_num*3]:\n",
    "                event = readConditions(subNum, 'gains', mat_gain_name, x)\n",
    "                event['condition'] = 'Gain'\n",
    "                event['zsvs'] = stats.zscore(event['svs'])                \n",
    "                totalEvent.append(event)\n",
    "        else:\n",
    "            print ('The condition ' + n + ' is not clear.')\n",
    "        \n",
    "        # the end result is an array of data sets per each run (i.e. block) - called totalEvent\n",
    "    return totalEvent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3a6a2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on the task rules, the subject ids that have Loss-Loss-Gain-Gain blocks on session 1, and Gain-Gain-Loss-Loss blocks on session 2\n",
    "# if the subject number ends in 1,2,5,6, or 9: LLGG on S1, GGLL on S2.\n",
    "# otherwise, GGLL on S1, LLGG on S2.\n",
    "\n",
    "LLGGs1_id = [11,12,15,16,19,21,22,25,29,31,32,36,39,41,42,45,46,51,55,56,61,62]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "708c233e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1stLoss [2021.0, 9.0, 21.0, 12.0, 16.0, 41.56100000000151]\n",
      "1stGain [2021.0, 9.0, 21.0, 12.0, 35.0, 5.401000000005297]\n",
      "3rdGain [2021.0, 9.0, 28.0, 11.0, 43.0, 8.215000000003783]\n",
      "3rdLoss [2021.0, 9.0, 28.0, 12.0, 1.0, 33.166000000004715]\n",
      "1stLoss\n",
      "1stLoss\n",
      "1stGain\n",
      "1stGain\n",
      "3rdGain\n",
      "3rdGain\n",
      "3rdLoss\n",
      "3rdLoss\n",
      "1stLoss [2021.0, 9.0, 13.0, 11.0, 54.0, 33.34100000000035]\n",
      "1stGain [2021.0, 9.0, 13.0, 12.0, 13.0, 48.234000000004016]\n",
      "3rdGain [2021.0, 9.0, 16.0, 13.0, 47.0, 37.95200000000477]\n",
      "3rdLoss [2021.0, 9.0, 16.0, 14.0, 6.0, 28.448000000003958]\n",
      "1stLoss\n",
      "1stLoss\n",
      "1stGain\n",
      "1stGain\n",
      "3rdGain\n",
      "3rdGain\n",
      "3rdLoss\n",
      "3rdLoss\n",
      "1stGain [2021.0, 10.0, 12.0, 12.0, 14.0, 46.859000000004016]\n",
      "1stLoss [2021.0, 10.0, 12.0, 12.0, 33.0, 22.447000000000116]\n",
      "3rdLoss [2021.0, 10.0, 14.0, 11.0, 58.0, 42.84000000000378]\n",
      "3rdGain [2021.0, 10.0, 14.0, 12.0, 17.0, 9.80000000000291]\n",
      "1stGain\n",
      "1stGain\n",
      "1stLoss\n",
      "1stLoss\n",
      "3rdLoss\n",
      "3rdLoss\n",
      "3rdGain\n",
      "3rdGain\n",
      "1stLoss [2021.0, 10.0, 21.0, 13.0, 2.0, 59.50200000000041]\n",
      "1stGain [2021.0, 10.0, 21.0, 13.0, 22.0, 9.89100000000326]\n",
      "3rdGain [2021.0, 10.0, 28.0, 11.0, 50.0, 23.137000000002445]\n",
      "3rdLoss [2021.0, 10.0, 28.0, 12.0, 8.0, 42.27400000000489]\n",
      "1stLoss\n",
      "1stLoss\n",
      "1stGain\n",
      "1stGain\n",
      "3rdGain\n",
      "3rdGain\n",
      "3rdLoss\n",
      "3rdLoss\n",
      "1stLoss [2021.0, 11.0, 9.0, 12.0, 32.0, 48.56900000000314]\n",
      "1stGain [2021.0, 11.0, 9.0, 12.0, 51.0, 10.874000000003434]\n",
      "3rdGain [2021.0, 11.0, 16.0, 12.0, 27.0, 21.848000000005413]\n",
      "3rdLoss [2021.0, 11.0, 16.0, 12.0, 45.0, 41.437000000005355]\n",
      "1stLoss\n",
      "1stLoss\n",
      "1stGain\n",
      "1stGain\n",
      "3rdGain\n",
      "3rdGain\n",
      "3rdLoss\n",
      "3rdLoss\n",
      "1stGain [2021.0, 10.0, 18.0, 8.0, 31.0, 31.681000000000495]\n",
      "1stLoss [2021.0, 10.0, 18.0, 8.0, 50.0, 4.527000000001863]\n",
      "3rdLoss [2021.0, 10.0, 19.0, 12.0, 22.0, 37.565999999998894]\n",
      "3rdGain [2021.0, 10.0, 19.0, 12.0, 40.0, 56.461999999999534]\n",
      "1stGain\n",
      "1stGain\n",
      "1stLoss\n",
      "1stLoss\n",
      "3rdLoss\n",
      "3rdLoss\n",
      "3rdGain\n",
      "3rdGain\n",
      "1stLoss [2021.0, 11.0, 30.0, 12.0, 29.0, 55.9890000000014]\n",
      "1stGain [2021.0, 11.0, 30.0, 12.0, 48.0, 20.260000000002037]\n",
      "3rdGain [2021.0, 12.0, 6.0, 9.0, 12.0, 52.382000000005064]\n",
      "3rdLoss [2021.0, 12.0, 6.0, 9.0, 31.0, 0.09200000000419095]\n",
      "1stLoss\n",
      "1stLoss\n",
      "1stGain\n",
      "1stGain\n",
      "3rdGain\n",
      "3rdGain\n",
      "3rdLoss\n",
      "3rdLoss\n",
      "1stGain [2021.0, 11.0, 18.0, 11.0, 58.0, 27.310000000004948]\n",
      "1stLoss [2021.0, 11.0, 18.0, 12.0, 16.0, 43.98500000000058]\n",
      "3rdLoss [2021.0, 12.0, 2.0, 11.0, 52.0, 35.317000000002736]\n",
      "3rdGain [2021.0, 12.0, 2.0, 12.0, 10.0, 54.17199999999866]\n",
      "1stGain\n",
      "1stGain\n",
      "1stLoss\n",
      "1stLoss\n",
      "3rdLoss\n",
      "3rdLoss\n",
      "3rdGain\n",
      "3rdGain\n",
      "1stLoss [2022.0, 2.0, 1.0, 12.0, 10.0, 36.72899999999936]\n",
      "1stGain [2022.0, 2.0, 1.0, 12.0, 28.0, 52.824000000000524]\n",
      "3rdGain [2022.0, 2.0, 3.0, 9.0, 12.0, 5.713000000003376]\n",
      "3rdLoss [2022.0, 2.0, 3.0, 9.0, 30.0, 24.42399999999907]\n",
      "1stLoss\n",
      "1stLoss\n",
      "1stGain\n",
      "1stGain\n",
      "3rdGain\n",
      "3rdGain\n",
      "3rdLoss\n",
      "3rdLoss\n",
      "1stLoss [2021.0, 12.0, 7.0, 12.0, 28.0, 44.007000000005064]\n",
      "1stGain [2021.0, 12.0, 7.0, 12.0, 47.0, 4.703000000001339]\n",
      "3rdGain [2021.0, 12.0, 9.0, 11.0, 50.0, 7.063000000001921]\n",
      "3rdLoss [2021.0, 12.0, 9.0, 12.0, 8.0, 9.343000000000757]\n",
      "1stLoss\n",
      "1stLoss\n",
      "1stGain\n",
      "1stGain\n",
      "3rdGain\n",
      "3rdGain\n",
      "3rdLoss\n",
      "3rdLoss\n",
      "1stGain [2022.0, 2.0, 3.0, 11.0, 31.0, 50.99300000000221]\n",
      "1stLoss [2022.0, 2.0, 3.0, 11.0, 49.0, 55.38100000000122]\n",
      "3rdLoss [2022.0, 2.0, 4.0, 8.0, 10.0, 20.19300000000294]\n",
      "3rdGain [2022.0, 2.0, 4.0, 8.0, 28.0, 35.19400000000314]\n",
      "1stGain\n",
      "1stGain\n",
      "1stLoss\n",
      "1stLoss\n",
      "3rdLoss\n",
      "3rdLoss\n",
      "3rdGain\n",
      "3rdGain\n",
      "1stLoss [2022.0, 2.0, 24.0, 11.0, 42.0, 24.372000000003027]\n",
      "1stGain [2022.0, 2.0, 24.0, 12.0, 0.0, 29.15899999999965]\n",
      "3rdGain [2022.0, 3.0, 1.0, 8.0, 47.0, 43.50600000000122]\n",
      "3rdLoss [2022.0, 3.0, 1.0, 9.0, 5.0, 47.96700000000055]\n",
      "1stLoss\n",
      "1stLoss\n",
      "1stGain\n",
      "1stGain\n",
      "3rdGain\n",
      "3rdGain\n",
      "3rdLoss\n",
      "3rdLoss\n",
      "1stGain [2022.0, 2.0, 17.0, 11.0, 47.0, 23.824000000000524]\n",
      "1stLoss [2022.0, 2.0, 17.0, 12.0, 5.0, 53.53199999999924]\n",
      "3rdLoss [2022.0, 2.0, 22.0, 12.0, 20.0, 23.544000000001688]\n",
      "3rdGain [2022.0, 2.0, 22.0, 12.0, 38.0, 42.124000000003434]\n",
      "1stGain\n",
      "1stGain\n",
      "1stLoss\n",
      "1stLoss\n",
      "3rdLoss\n",
      "3rdLoss\n",
      "3rdGain\n",
      "3rdGain\n",
      "1stGain [2022.0, 3.0, 1.0, 12.0, 19.0, 12.872000000003027]\n",
      "1stLoss [2022.0, 3.0, 1.0, 12.0, 37.0, 21.868000000002212]\n",
      "3rdLoss [2022.0, 3.0, 2.0, 8.0, 58.0, 32.449000000000524]\n",
      "3rdGain [2022.0, 3.0, 2.0, 9.0, 16.0, 41.55800000000454]\n",
      "1stGain\n",
      "1stGain\n",
      "1stLoss\n",
      "1stLoss\n",
      "3rdLoss\n",
      "3rdLoss\n",
      "3rdGain\n",
      "3rdGain\n",
      "1stLoss [2022.0, 2.0, 15.0, 12.0, 10.0, 9.06300000000192]\n",
      "1stGain [2022.0, 2.0, 15.0, 12.0, 28.0, 38.90200000000186]\n",
      "3rdGain [2022.0, 2.0, 18.0, 8.0, 22.0, 14.936000000001513]\n",
      "3rdLoss [2022.0, 2.0, 18.0, 8.0, 40.0, 23.842000000000553]\n",
      "1stLoss\n",
      "1stLoss\n",
      "1stGain\n",
      "1stGain\n",
      "3rdGain\n",
      "3rdGain\n",
      "3rdLoss\n",
      "3rdLoss\n",
      "1stGain [2022.0, 2.0, 22.0, 8.0, 35.0, 47.01800000000003]\n",
      "1stLoss [2022.0, 2.0, 22.0, 8.0, 54.0, 0.049000000002706656]\n",
      "3rdLoss [2022.0, 2.0, 23.0, 8.0, 12.0, 46.625]\n",
      "3rdGain [2022.0, 2.0, 23.0, 8.0, 31.0, 3.569000000003143]\n",
      "1stGain\n",
      "1stGain\n",
      "1stLoss\n",
      "1stLoss\n",
      "3rdLoss\n",
      "3rdLoss\n",
      "3rdGain\n",
      "3rdGain\n",
      "1stLoss [2022.0, 3.0, 8.0, 12.0, 50.0, 39.903000000005704]\n",
      "1stGain [2022.0, 3.0, 8.0, 13.0, 8.0, 51.94400000000314]\n",
      "3rdGain [2022.0, 3.0, 10.0, 11.0, 43.0, 33.85399999999936]\n",
      "3rdLoss [2022.0, 3.0, 10.0, 12.0, 1.0, 49.22899999999936]\n",
      "1stLoss\n",
      "1stLoss\n",
      "1stGain\n",
      "1stGain\n",
      "3rdGain\n",
      "3rdGain\n",
      "3rdLoss\n",
      "3rdLoss\n",
      "1stLoss [2022.0, 3.0, 3.0, 11.0, 46.0, 51.207000000002154]\n",
      "1stGain [2022.0, 3.0, 3.0, 12.0, 4.0, 54.78199999999924]\n",
      "3rdGain [2022.0, 3.0, 14.0, 10.0, 37.0, 54.34800000000541]\n",
      "3rdLoss [2022.0, 3.0, 14.0, 10.0, 55.0, 56.11899999999878]\n",
      "1stLoss\n",
      "1stLoss\n",
      "1stGain\n",
      "1stGain\n",
      "3rdGain\n",
      "3rdGain\n",
      "3rdLoss\n",
      "3rdLoss\n",
      "1stLoss [2022.0, 3.0, 30.0, 8.0, 31.0, 5.253000000000611]\n",
      "1stGain [2022.0, 3.0, 30.0, 8.0, 49.0, 9.546000000002095]\n",
      "3rdGain [2022.0, 4.0, 6.0, 8.0, 17.0, 33.284999999999854]\n",
      "3rdLoss [2022.0, 4.0, 6.0, 8.0, 35.0, 45.71600000000035]\n",
      "1stLoss\n",
      "1stLoss\n",
      "1stGain\n",
      "1stGain\n",
      "3rdGain\n",
      "3rdGain\n",
      "3rdLoss\n",
      "3rdLoss\n",
      "1stLoss [2022.0, 3.0, 24.0, 14.0, 24.0, 49.84000000000378]\n",
      "1stGain [2022.0, 3.0, 24.0, 14.0, 43.0, 2.264999999999418]\n",
      "3rdGain [2022.0, 3.0, 25.0, 11.0, 43.0, 31.416000000004715]\n",
      "3rdLoss [2022.0, 3.0, 25.0, 12.0, 1.0, 44.28100000000268]\n",
      "1stLoss\n",
      "1stLoss\n",
      "1stGain\n",
      "1stGain\n",
      "3rdGain\n",
      "3rdGain\n",
      "3rdLoss\n",
      "3rdLoss\n",
      "1stGain [2022.0, 4.0, 26.0, 12.0, 18.0, 17.046000000002095]\n",
      "1stLoss [2022.0, 4.0, 26.0, 12.0, 36.0, 25.413000000000466]\n",
      "3rdLoss [2022.0, 4.0, 28.0, 11.0, 28.0, 33.14900000000489]\n",
      "3rdGain [2022.0, 4.0, 28.0, 11.0, 46.0, 41.663000000000466]\n",
      "1stGain\n",
      "1stGain\n",
      "1stLoss\n",
      "1stLoss\n",
      "3rdLoss\n",
      "3rdLoss\n",
      "3rdGain\n",
      "3rdGain\n",
      "1stLoss [2022.0, 3.0, 29.0, 12.0, 32.0, 36.1050000000032]\n",
      "1stGain [2022.0, 3.0, 29.0, 12.0, 51.0, 20.050999999999476]\n",
      "3rdGain [2022.0, 4.0, 14.0, 10.0, 57.0, 20.574000000000524]\n",
      "3rdLoss [2022.0, 4.0, 14.0, 11.0, 15.0, 28.455999999998312]\n",
      "1stLoss\n",
      "1stLoss\n",
      "1stGain\n",
      "1stGain\n",
      "3rdGain\n",
      "3rdGain\n",
      "3rdLoss\n",
      "3rdLoss\n",
      "1stLoss [2022.0, 5.0, 3.0, 12.0, 22.0, 59.565999999998894]\n",
      "1stGain [2022.0, 5.0, 3.0, 12.0, 41.0, 44.74799999999959]\n",
      "3rdGain [2022.0, 5.0, 5.0, 11.0, 43.0, 24.300999999999476]\n",
      "3rdLoss [2022.0, 5.0, 5.0, 12.0, 1.0, 46.520000000004075]\n",
      "1stLoss\n",
      "1stLoss\n",
      "1stGain\n",
      "1stGain\n",
      "3rdGain\n",
      "3rdGain\n",
      "3rdLoss\n",
      "3rdLoss\n",
      "1stGain [2022.0, 5.0, 10.0, 12.0, 34.0, 13.760000000002037]\n",
      "1stLoss [2022.0, 5.0, 10.0, 12.0, 53.0, 1.6490000000048894]\n",
      "3rdLoss [2022.0, 5.0, 27.0, 10.0, 35.0, 35.103000000002794]\n",
      "3rdGain [2022.0, 5.0, 27.0, 10.0, 53.0, 38.80800000000454]\n",
      "1stGain\n",
      "1stGain\n",
      "1stLoss\n",
      "1stLoss\n",
      "3rdLoss\n",
      "3rdLoss\n",
      "3rdGain\n",
      "3rdGain\n",
      "1stLoss [2022.0, 5.0, 17.0, 16.0, 47.0, 12.082000000002154]\n",
      "1stGain [2022.0, 5.0, 17.0, 17.0, 5.0, 18.2870000000039]\n",
      "3rdGain [2022.0, 5.0, 31.0, 10.0, 56.0, 34.741000000001804]\n",
      "3rdLoss [2022.0, 5.0, 31.0, 11.0, 14.0, 42.47899999999936]\n",
      "1stLoss\n",
      "1stLoss\n",
      "1stGain\n",
      "1stGain\n",
      "3rdGain\n",
      "3rdGain\n",
      "3rdLoss\n",
      "3rdLoss\n",
      "1stLoss [2022.0, 5.0, 24.0, 12.0, 17.0, 29.84700000000157]\n",
      "1stGain [2022.0, 5.0, 24.0, 12.0, 35.0, 42.03199999999924]\n",
      "3rdGain [2022.0, 5.0, 26.0, 11.0, 28.0, 21.507000000005064]\n",
      "3rdLoss [2022.0, 5.0, 26.0, 11.0, 46.0, 21.872000000003027]\n",
      "1stLoss\n",
      "1stLoss\n",
      "1stGain\n",
      "1stGain\n",
      "3rdGain\n",
      "3rdGain\n",
      "3rdLoss\n",
      "3rdLoss\n",
      "1stGain [2022.0, 6.0, 7.0, 12.0, 39.0, 32.358000000000175]\n",
      "1stLoss [2022.0, 6.0, 7.0, 12.0, 57.0, 36.050999999999476]\n",
      "3rdLoss [2022.0, 6.0, 8.0, 10.0, 41.0, 53.70900000000256]\n",
      "3rdGain [2022.0, 6.0, 8.0, 11.0, 0.0, 4.449000000000524]\n",
      "1stGain\n",
      "1stGain\n",
      "1stLoss\n",
      "1stLoss\n",
      "3rdLoss\n",
      "3rdLoss\n",
      "3rdGain\n",
      "3rdGain\n",
      "1stGain [2022.0, 6.0, 14.0, 12.0, 18.0, 10.99500000000262]\n",
      "1stLoss [2022.0, 6.0, 14.0, 12.0, 36.0, 15.13799999999901]\n",
      "3rdLoss [2022.0, 6.0, 16.0, 11.0, 43.0, 1.1920000000027358]\n",
      "3rdGain [2022.0, 6.0, 16.0, 12.0, 1.0, 13.173000000002503]\n",
      "1stGain\n",
      "1stGain\n",
      "1stLoss\n",
      "1stLoss\n",
      "3rdLoss\n",
      "3rdLoss\n",
      "3rdGain\n",
      "3rdGain\n",
      "1stGain [2022.0, 7.0, 19.0, 10.0, 53.0, 41.45799999999872]\n",
      "1stLoss [2022.0, 7.0, 19.0, 11.0, 12.0, 3.4250000000029104]\n",
      "3rdLoss [2022.0, 7.0, 21.0, 11.0, 2.0, 14.59100000000035]\n",
      "3rdGain [2022.0, 7.0, 21.0, 11.0, 20.0, 12.87800000000425]\n",
      "1stGain\n",
      "1stGain\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1stLoss\n",
      "1stLoss\n",
      "3rdLoss\n",
      "3rdLoss\n",
      "3rdGain\n",
      "3rdGain\n",
      "1stLoss [2022.0, 7.0, 26.0, 12.0, 15.0, 27.054000000003725]\n",
      "1stGain [2022.0, 7.0, 26.0, 12.0, 39.0, 13.447000000000116]\n",
      "3rdGain [2022.0, 7.0, 28.0, 11.0, 52.0, 14.394000000000233]\n",
      "3rdLoss [2022.0, 7.0, 28.0, 12.0, 10.0, 28.207000000002154]\n",
      "1stLoss\n",
      "1stLoss\n",
      "1stGain\n",
      "1stGain\n",
      "3rdGain\n",
      "3rdGain\n",
      "3rdLoss\n",
      "3rdLoss\n",
      "1stLoss [2022.0, 8.0, 22.0, 15.0, 53.0, 45.93800000000192]\n",
      "1stGain [2022.0, 8.0, 22.0, 16.0, 12.0, 21.244000000006054]\n",
      "3rdGain [2022.0, 8.0, 29.0, 15.0, 42.0, 48.10000000000582]\n",
      "3rdLoss [2022.0, 8.0, 29.0, 16.0, 0.0, 50.63100000000122]\n",
      "1stLoss\n",
      "1stLoss\n",
      "1stGain\n",
      "1stGain\n",
      "3rdGain\n",
      "3rdGain\n",
      "3rdLoss\n",
      "3rdLoss\n",
      "1stLoss [2022.0, 8.0, 17.0, 16.0, 7.0, 14.233000000000175]\n",
      "1stGain [2022.0, 8.0, 17.0, 16.0, 25.0, 16.61300000000483]\n",
      "3rdGain [2022.0, 8.0, 18.0, 11.0, 52.0, 30.260999999998603]\n",
      "3rdLoss [2022.0, 8.0, 18.0, 12.0, 10.0, 37.03900000000431]\n",
      "1stLoss\n",
      "1stLoss\n",
      "1stGain\n",
      "1stGain\n",
      "3rdGain\n",
      "3rdGain\n",
      "3rdLoss\n",
      "3rdLoss\n",
      "1stGain [2022.0, 8.0, 30.0, 12.0, 22.0, 5.8070000000006985]\n",
      "1stLoss [2022.0, 8.0, 30.0, 12.0, 40.0, 13.952000000004773]\n",
      "3rdLoss [2022.0, 9.0, 8.0, 16.0, 44.0, 32.21700000000419]\n",
      "3rdGain [2022.0, 9.0, 8.0, 17.0, 2.0, 24.388000000006286]\n",
      "1stGain\n",
      "1stGain\n",
      "1stLoss\n",
      "1stLoss\n",
      "3rdLoss\n",
      "3rdLoss\n",
      "3rdGain\n",
      "3rdGain\n",
      "1stLoss [2022.0, 9.0, 27.0, 12.0, 32.0, 57.19000000000233]\n",
      "1stGain [2022.0, 9.0, 27.0, 12.0, 50.0, 55.3550000000032]\n",
      "3rdGain [2022.0, 9.0, 29.0, 11.0, 55.0, 30.848000000005413]\n",
      "3rdLoss [2022.0, 9.0, 29.0, 12.0, 13.0, 32.64100000000326]\n",
      "1stLoss\n",
      "1stLoss\n",
      "1stGain\n",
      "1stGain\n",
      "3rdGain\n",
      "3rdGain\n",
      "3rdLoss\n",
      "3rdLoss\n",
      "1stLoss [2022.0, 10.0, 10.0, 10.0, 56.0, 43.50100000000384]\n",
      "1stGain [2022.0, 10.0, 10.0, 11.0, 14.0, 45.51299999999901]\n",
      "3rdGain [2022.0, 10.0, 13.0, 10.0, 18.0, 55.62600000000384]\n",
      "3rdLoss [2022.0, 10.0, 13.0, 10.0, 36.0, 56.83299999999872]\n",
      "1stLoss\n",
      "1stLoss\n",
      "1stGain\n",
      "1stGain\n",
      "3rdGain\n",
      "3rdGain\n",
      "3rdLoss\n",
      "3rdLoss\n"
     ]
    }
   ],
   "source": [
    "for sub_id in sub_num:\n",
    "    totalEvent_sub = organizeBlocks(sub_id)\n",
    "    \n",
    "    #write into csv based on conditions of the RAID protocol\n",
    "    if sub_id in LLGGs1_id:\n",
    "        # LLGG on ses1, GGLL on ses2\n",
    "        for task_id in range(8):\n",
    "            if task_id == 2:\n",
    "                pd.DataFrame(totalEvent_sub[task_id]).to_csv(os.path.join(out_root, '01102023', 'sub-' + str(sub_id) + '_ses-1_task-gain1_cond.csv'), \n",
    "                                                         index = False, sep = '\\t') \n",
    "            elif task_id == 3:\n",
    "                pd.DataFrame(totalEvent_sub[task_id]).to_csv(os.path.join(out_root, '01102023', 'sub-' + str(sub_id) + '_ses-1_task-gain2_cond.csv'), \n",
    "                                                         index = False, sep = '\\t')            \n",
    "            elif task_id == 4:\n",
    "                pd.DataFrame(totalEvent_sub[task_id]).to_csv(os.path.join(out_root, '01102023', 'sub-' + str(sub_id) + '_ses-2_task-gain1_cond.csv'), \n",
    "                                                         index = False, sep = '\\t')            \n",
    "            elif task_id == 5:\n",
    "                pd.DataFrame(totalEvent_sub[task_id]).to_csv(os.path.join(out_root, '01102023', 'sub-' + str(sub_id) + '_ses-2_task-gain2_cond.csv'), \n",
    "                                                         index = False, sep = '\\t')            \n",
    "            elif task_id == 0:\n",
    "                pd.DataFrame(totalEvent_sub[task_id]).to_csv(os.path.join(out_root, '01102023', 'sub-' + str(sub_id) + '_ses-1_task-loss1_cond.csv'), \n",
    "                                                         index = False, sep = '\\t') \n",
    "            elif task_id == 1:\n",
    "                pd.DataFrame(totalEvent_sub[task_id]).to_csv(os.path.join(out_root, '01102023', 'sub-' + str(sub_id) + '_ses-1_task-loss2_cond.csv'), \n",
    "                                                         index = False, sep = '\\t')             \n",
    "            elif task_id == 6:\n",
    "                pd.DataFrame(totalEvent_sub[task_id]).to_csv(os.path.join(out_root, '01102023', 'sub-' + str(sub_id) + '_ses-2_task-loss1_cond.csv'), \n",
    "                                                         index = False, sep = '\\t')             \n",
    "            elif task_id == 7:\n",
    "                pd.DataFrame(totalEvent_sub[task_id]).to_csv(os.path.join(out_root, '01102023', 'sub-' + str(sub_id) + '_ses-2_task-loss2_cond.csv'), \n",
    "                                                         index = False, sep = '\\t')\n",
    "    else:\n",
    "        # GGLL on ses1, LLGG on ses2\n",
    "        for task_id in range(8):\n",
    "            if task_id == 2:\n",
    "                pd.DataFrame(totalEvent_sub[task_id]).to_csv(os.path.join(out_root, '01102023', 'sub-' + str(sub_id) + '_ses-1_task-loss1_cond.csv'), \n",
    "                                                         index = False, sep = '\\t') \n",
    "            elif task_id == 3:\n",
    "                pd.DataFrame(totalEvent_sub[task_id]).to_csv(os.path.join(out_root, '01102023', 'sub-' + str(sub_id) + '_ses-1_task-loss2_cond.csv'), \n",
    "                                                         index = False, sep = '\\t')            \n",
    "            elif task_id == 4:\n",
    "                pd.DataFrame(totalEvent_sub[task_id]).to_csv(os.path.join(out_root, '01102023', 'sub-' + str(sub_id) + '_ses-2_task-loss1_cond.csv'), \n",
    "                                                         index = False, sep = '\\t')            \n",
    "            elif task_id == 5:\n",
    "                pd.DataFrame(totalEvent_sub[task_id]).to_csv(os.path.join(out_root, '01102023', 'sub-' + str(sub_id) + '_ses-2_task-loss2_cond.csv'), \n",
    "                                                         index = False, sep = '\\t')            \n",
    "            elif task_id == 0:\n",
    "                pd.DataFrame(totalEvent_sub[task_id]).to_csv(os.path.join(out_root, '01102023', 'sub-' + str(sub_id) + '_ses-1_task-gain1_cond.csv'), \n",
    "                                                         index = False, sep = '\\t') \n",
    "            elif task_id == 1:\n",
    "                pd.DataFrame(totalEvent_sub[task_id]).to_csv(os.path.join(out_root, '01102023', 'sub-' + str(sub_id) + '_ses-1_task-gain2_cond.csv'), \n",
    "                                                         index = False, sep = '\\t')             \n",
    "            elif task_id == 6:\n",
    "                pd.DataFrame(totalEvent_sub[task_id]).to_csv(os.path.join(out_root, '01102023', 'sub-' + str(sub_id) + '_ses-2_task-gain1_cond.csv'), \n",
    "                                                         index = False, sep = '\\t')             \n",
    "            elif task_id == 7:\n",
    "                pd.DataFrame(totalEvent_sub[task_id]).to_csv(os.path.join(out_root, '01102023', 'sub-' + str(sub_id) + '_ses-2_task-gain2_cond.csv'), \n",
    "                                                         index = False, sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea531ae",
   "metadata": {},
   "source": [
    "Remember to double check each event file for one participant!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
