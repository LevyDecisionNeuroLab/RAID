{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b5421dd",
   "metadata": {},
   "source": [
    "For the RAID study, this script will return, for each participant, choice proportions for:\n",
    "* p(risk)\n",
    "* p(ambig)\n",
    "* p(ambig_corr)\n",
    "* p(risk_25)\n",
    "* p(risk_50)\n",
    "* p(risk_75)\n",
    "* p(amb_24)\n",
    "* p(amb_50)\n",
    "* p(amb_74)\n",
    "* p(amb_24_corr)\n",
    "* p(amb_50_corr)\n",
    "* p(amb_74_corr)\n",
    "\n",
    "Under:\n",
    "* gains\n",
    "* losses\n",
    "* combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6559dff9",
   "metadata": {},
   "source": [
    "Necessary inputs are the MATLAB data files for each participant, e.g. for `subject 10`:\n",
    "* `RA_GAINS_10.mat` that has all the data from 2 gain blocks on day 1 and 2 gain blocks on day 2\n",
    "* `RA_LOSS_10.mat` that has all the data from 2 loss blocks on day 1 and 2 loss blocks on day 2\n",
    "\n",
    "These files for all participants should be in the **same** directory, referred to as `data_behav_root` in the script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3368644",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.io as spio\n",
    "from glob import glob\n",
    "from scipy import stats\n",
    "import datetime\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "773f85c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory containing MATLAB data files\n",
    "data_behav_root = 'D:\\\\Chelsea\\\\Projects_in_the_lab\\\\RAID\\\\behavioral'\n",
    "\n",
    "# output directory for saving your dataset\n",
    "out_root = 'D:\\\\Chelsea\\\\Projects_in_the_lab\\\\RAID\\\\output\\\\files_for_megan'\n",
    "\n",
    "# subjects for analysis\n",
    "sub_num = [11,12,13,15,16,17,19,20,21,22,24,25,27,28,29,30,31,32,36,39,40,41,42,43,45,46,47,48,50,51,55,56,57,61,62]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb85c900",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _todict(matobj):\n",
    "    '''\n",
    "    Author: Or\n",
    "    \n",
    "    A recursive function which constructs from matobjects nested dictionaries\n",
    "    '''\n",
    "    dict = {}\n",
    "    for strg in matobj._fieldnames:\n",
    "        elem = matobj.__dict__[strg]\n",
    "        if isinstance(elem, spio.matlab.mio5_params.mat_struct):\n",
    "            dict[strg] = _todict(elem)\n",
    "        else:\n",
    "            dict[strg] = elem\n",
    "    return dict\n",
    "\n",
    "def _check_keys(dict):\n",
    "    '''\n",
    "    Author: Or\n",
    "    \n",
    "    checks if entries in dictionary are mat-objects. If yes todict is called to change them to nested dictionaries\n",
    "    '''\n",
    "    for key in dict:\n",
    "        if isinstance(dict[key], spio.matlab.mio5_params.mat_struct):\n",
    "            dict[key] = _todict(dict[key])\n",
    "    return dict \n",
    "\n",
    "def loadmat(filename):\n",
    "    '''\n",
    "    Author: Or\n",
    "    \n",
    "    this function should be called instead of direct spio.loadmat\n",
    "    as it cures the problem of not properly recovering python dictionaries\n",
    "    from mat files. It calls the function check keys to cure all entries\n",
    "    which are still mat-objects\n",
    "    \n",
    "    from: `StackOverflow <http://stackoverflow.com/questions/7008608/scipy-io-loadmat-nested-structures-i-e-dictionaries>`_\n",
    "    '''\n",
    "    data = spio.loadmat(filename, struct_as_record=False, squeeze_me=True)\n",
    "    return _check_keys(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c168d9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readConditions(subNum, domain, matFile):\n",
    "    \"\"\" read conditions\n",
    "    \n",
    "    Parameters\n",
    "    -------------\n",
    "    subNum: subject id\n",
    "    domain: domain name, 'gains' or 'loss'\n",
    "    matFile: filename\n",
    "    \n",
    "    Return\n",
    "    -------------\n",
    "    events\n",
    "    \"\"\"\n",
    "    metaData = loadmat(matFile)       \n",
    "    data_keyname = list(metaData.keys())[3]\n",
    "    \n",
    "    proportions = []\n",
    "    p_risk = []\n",
    "    p_ambig = []\n",
    "    p_ambig_corr = []\n",
    "    risk_25 = []\n",
    "    risk_50 = []\n",
    "    risk_75 = []\n",
    "    amb_24 = []\n",
    "    amb_50 = []\n",
    "    amb_74 = []\n",
    "    amb_24_corr = []\n",
    "    amb_50_corr = []\n",
    "    amb_74_corr = []\n",
    "   \n",
    "    ambigs = metaData[data_keyname]['ambigs']\n",
    "    probs = metaData[data_keyname]['probs']\n",
    "    if domain == 'gains':\n",
    "        vals = metaData[data_keyname]['vals']\n",
    "    else:\n",
    "        vals = -1*metaData[data_keyname]['vals']\n",
    "    choice = metaData[data_keyname]['choice']\n",
    "    refside = metaData[data_keyname]['refSide']\n",
    "    \n",
    "    # calculate response from choice and refside\n",
    "    resp = np.ones(choice.shape) # 1-choose lottery\n",
    "    resp[choice == refside] = 0 # 0-choose reference\n",
    "    resp[choice == 0] = 2 # 2-no response\n",
    "    \n",
    "    vals = np.delete(vals, np.where(resp==2))\n",
    "    ambigs = np.delete(ambigs, np.where(resp==2))\n",
    "    probs = np.delete(probs, np.where(resp==2))\n",
    "    new_array = np.delete(resp, np.where(resp == 2))\n",
    "    \n",
    "    risk_25 = np.mean(new_array[(vals !=5) & (ambigs ==0) & (probs ==0.25)])\n",
    "    risk_50 = np.mean(new_array[(vals !=5) & (ambigs ==0) & (probs ==0.5)])\n",
    "    risk_75 = np.mean(new_array[(vals !=5) & (ambigs ==0) & (probs ==0.75)])\n",
    "    \n",
    "    amb_24 = np.mean(new_array[(vals !=5) & (ambigs ==0.24)])\n",
    "    amb_50 = np.mean(new_array[(vals !=5) & (ambigs ==0.5)])\n",
    "    amb_74 = np.mean(new_array[(vals !=5) & (ambigs ==0.74)])\n",
    "    \n",
    "    amb_24_corr = np.mean(new_array[(vals !=5) & (ambigs ==0.24)]) - np.mean(new_array[(vals !=5) & (ambigs ==0) & (probs ==0.5)])\n",
    "    amb_50_corr = np.mean(new_array[(vals !=5) & (ambigs ==0.5)]) - np.mean(new_array[(vals !=5) & (ambigs ==0) & (probs ==0.5)])\n",
    "    amb_74_corr = np.mean(new_array[(vals !=5) & (ambigs ==0.74)]) - np.mean(new_array[(vals !=5) & (ambigs ==0) & (probs ==0.5)])\n",
    "    \n",
    "    p_risk = np.mean(new_array[(vals !=5) & (ambigs ==0)])\n",
    "    p_ambig = np.mean(new_array[(vals !=5) & (ambigs !=0)])\n",
    "    p_ambig_corr = np.mean(new_array[(vals !=5) & (ambigs !=0)]) - np.mean(new_array[(vals !=5) & (ambigs ==0) & (probs ==0.5)])\n",
    "    \n",
    "    events= pd.DataFrame({'sub':subNum,\n",
    "                          'p(risk)':p_risk, 'p(ambig)':p_ambig, 'p(ambig_corr)':p_ambig_corr, \n",
    "                          'p(risk_25)': risk_25, \n",
    "                          'p(risk_50)': risk_50, \n",
    "                          'p(risk_75)': risk_75, \n",
    "                          'p(amb_24)': amb_24,\n",
    "                          'p(amb_50)': amb_50,\n",
    "                          'p(amb_74)': amb_74,\n",
    "                          'p(amb_24_corr)': amb_24_corr,\n",
    "                          'p(amb_50_corr)': amb_50_corr,\n",
    "                          'p(amb_74_corr)': amb_74_corr}, index = [0]) # building data frame from what we took. Removing first row because its not used. \n",
    "    \n",
    "    return events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c572e5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def organizeBlocks(subNum):\n",
    "\n",
    "    mat_loss_name = os.path.join(data_behav_root, 'RA_LOSS_%s.mat' %subNum)    \n",
    "    mat_gain_name = os.path.join(data_behav_root, 'RA_GAINS_%s.mat' %subNum)    \n",
    "    \n",
    "    metaDataLoss = loadmat(mat_loss_name)\n",
    "    data_loss_keyname = list(metaDataLoss.keys())[3]\n",
    "    metaDataGain = loadmat(mat_gain_name)\n",
    "    data_gain_keyname = list(metaDataGain.keys())[3]\n",
    "    \n",
    "    totalEvent_gain = readConditions(subNum, 'gains', mat_gain_name)\n",
    "    totalEvent_loss = readConditions(subNum, 'loss', mat_loss_name)\n",
    "    \n",
    "    return totalEvent_gain, totalEvent_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8499a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the participants you want to analyze\n",
    "sub_num = [11,12,13,15,16,17,19,20,21,22,24,25,27,28,29,30,31,32,36,39,40,41,42,43,45,46,47,48,50,51,55,56,57,61,62]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c5485cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sub_id in sub_num:\n",
    "    sub_gain, sub_loss = organizeBlocks(sub_id)\n",
    "    sub_total = pd.DataFrame((sub_gain.append(sub_loss)).mean(axis=0)).transpose()\n",
    "    \n",
    "    if sub_id ==sub_num[0]:\n",
    "        total_gain = pd.DataFrame(sub_gain)\n",
    "        total_loss = pd.DataFrame(sub_loss)\n",
    "        total_both = pd.DataFrame(sub_total)\n",
    "    else:\n",
    "        total_gain = total_gain.append(pd.DataFrame(sub_gain))\n",
    "        total_loss = total_loss.append(pd.DataFrame(sub_loss))\n",
    "        total_both = total_both.append(pd.DataFrame(sub_total))\n",
    "    \n",
    "pd.DataFrame(total_gain).to_excel(os.path.join(out_root, 'task_proportions_gains_test.xlsx'),\n",
    "                                     index = False) \n",
    "pd.DataFrame(total_loss).to_excel(os.path.join(out_root, 'task_proportions_losses_test.xlsx'),\n",
    "                                     index = False) \n",
    "pd.DataFrame(total_both).to_excel(os.path.join(out_root, 'task_proportions_both_test.xlsx'),\n",
    "                                     index = False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
